"""
æµ‹è¯•Sparshè§¦è§‰ç¼–ç å™¨æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½é¢„è®­ç»ƒæƒé‡
"""

import sys
import os
import torch

# Add paths
TACEX_PATH = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1"
SPARSH_PATH = "/home/pi-zero/isaac-sim/sparsh"

if TACEX_PATH not in sys.path:
    sys.path.insert(0, TACEX_PATH)
if SPARSH_PATH not in sys.path:
    sys.path.insert(0, SPARSH_PATH)

from network.tactile_feature_extractor import SparshTactileEncoder, DualSensorSparshEncoder

def test_checkpoint_loading():
    """æµ‹è¯•checkpointåŠ è½½"""
    print("=" * 80)
    print("æµ‹è¯•1: æ£€æŸ¥checkpointæ–‡ä»¶")
    print("=" * 80)

    checkpoint_path = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1/network/epoch-0021.pth"

    if not os.path.exists(checkpoint_path):
        print(f"âŒ Checkpointä¸å­˜åœ¨: {checkpoint_path}")
        return False

    print(f"âœ“ Checkpointå­˜åœ¨: {checkpoint_path}")

    # åŠ è½½checkpointæŸ¥çœ‹ç»“æ„
    print("\nåŠ è½½checkpoint...")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')

    print(f"\nCheckpoint keys: {list(checkpoint.keys())}")

    if 'model_encoder' in checkpoint:
        print(f"\nâœ“ å‘ç° 'model_encoder' é”®")
        encoder_state = checkpoint['model_encoder']
        print(f"  Encoder state_dictåŒ…å« {len(encoder_state)} ä¸ªå‚æ•°")
        print(f"\n  å‰10ä¸ªå‚æ•°é”®:")
        for i, key in enumerate(list(encoder_state.keys())[:10]):
            print(f"    {i+1}. {key}: {encoder_state[key].shape}")
    else:
        print(f"\nâŒ æœªå‘ç° 'model_encoder' é”®")
        print(f"  å¯ç”¨çš„é”®: {list(checkpoint.keys())}")

    if 'model_task' in checkpoint:
        print(f"\nâœ“ å‘ç° 'model_task' é”®")
        task_state = checkpoint['model_task']
        print(f"  Task state_dictåŒ…å« {len(task_state)} ä¸ªå‚æ•°")

    return True


def test_encoder_creation():
    """æµ‹è¯•ç¼–ç å™¨åˆ›å»º"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: åˆ›å»ºç¼–ç å™¨ï¼ˆä¸åŠ è½½æƒé‡ï¼‰")
    print("=" * 80)

    try:
        print("\nåˆ›å»ºSparshTactileEncoder...")
        encoder = SparshTactileEncoder(
            checkpoint_path=None,  # ä¸åŠ è½½æƒé‡
            output_dim=256,
            freeze_encoder=True
        )

        print(f"âœ“ ç¼–ç å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æ€»å‚æ•°: {sum(p.numel() for p in encoder.parameters()) / 1e6:.2f}M")

        # æµ‹è¯•forward
        print("\næµ‹è¯•forwardä¼ æ’­...")
        dummy_input = torch.randn(2, 3, 32, 32)  # 2ä¸ªæ ·æœ¬, 3é€šé“, 32x32
        with torch.no_grad():
            output = encoder(dummy_input)

        print(f"âœ“ ForwardæˆåŠŸ")
        print(f"  è¾“å…¥shape: {dummy_input.shape}")
        print(f"  è¾“å‡ºshape: {output.shape}")
        print(f"  æœŸæœ›è¾“å‡ºshape: (2, 256)")

        if output.shape == (2, 256):
            print("âœ“ è¾“å‡ºshapeæ­£ç¡®")
            return True
        else:
            print(f"âŒ è¾“å‡ºshapeä¸æ­£ç¡®: æœŸæœ›(2, 256), å®é™…{output.shape}")
            return False

    except Exception as e:
        print(f"âŒ ç¼–ç å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_encoder_with_checkpoint():
    """æµ‹è¯•åŠ è½½checkpointçš„ç¼–ç å™¨"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: åˆ›å»ºç¼–ç å™¨å¹¶åŠ è½½checkpoint")
    print("=" * 80)

    checkpoint_path = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1/network/epoch-0021.pth"

    try:
        print("\nåˆ›å»ºSparshTactileEncoderå¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡...")
        encoder = SparshTactileEncoder(
            checkpoint_path=checkpoint_path,
            output_dim=256,
            freeze_encoder=True
        )

        print(f"\nâœ“ ç¼–ç å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æ€»å‚æ•°: {sum(p.numel() for p in encoder.parameters()) / 1e6:.2f}M")
        print(f"  å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in encoder.parameters() if p.requires_grad) / 1e6:.2f}M")

        # æµ‹è¯•forward
        print("\næµ‹è¯•forwardä¼ æ’­...")
        dummy_input = torch.randn(4, 3, 32, 32)  # 4ä¸ªæ ·æœ¬
        with torch.no_grad():
            output = encoder(dummy_input)

        print(f"âœ“ ForwardæˆåŠŸ")
        print(f"  è¾“å…¥shape: {dummy_input.shape}")
        print(f"  è¾“å‡ºshape: {output.shape}")
        print(f"  è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
        print(f"  è¾“å‡ºå‡å€¼: {output.mean():.3f}")
        print(f"  è¾“å‡ºæ ‡å‡†å·®: {output.std():.3f}")

        return True

    except Exception as e:
        print(f"âŒ åŠ è½½checkpointå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dual_encoder():
    """æµ‹è¯•åŒä¼ æ„Ÿå™¨ç¼–ç å™¨"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•4: åˆ›å»ºåŒä¼ æ„Ÿå™¨ç¼–ç å™¨")
    print("=" * 80)

    checkpoint_path = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1/network/epoch-0021.pth"

    try:
        print("\nåˆ›å»ºDualSensorSparshEncoder...")
        dual_encoder = DualSensorSparshEncoder(
            checkpoint_path=checkpoint_path,
            single_encoder_dim=256,
            fusion_dim=512,
            freeze_encoder=True
        )

        print(f"\nâœ“ åŒä¼ æ„Ÿå™¨ç¼–ç å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æ€»å‚æ•°: {sum(p.numel() for p in dual_encoder.parameters()) / 1e6:.2f}M")
        print(f"  å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in dual_encoder.parameters() if p.requires_grad) / 1e6:.2f}M")

        # æµ‹è¯•forward
        print("\næµ‹è¯•forwardä¼ æ’­...")
        left_input = torch.randn(4, 3, 32, 32)
        right_input = torch.randn(4, 3, 32, 32)

        with torch.no_grad():
            fused_output = dual_encoder(left_input, right_input)

        print(f"âœ“ ForwardæˆåŠŸ")
        print(f"  å·¦ä¼ æ„Ÿå™¨è¾“å…¥shape: {left_input.shape}")
        print(f"  å³ä¼ æ„Ÿå™¨è¾“å…¥shape: {right_input.shape}")
        print(f"  èåˆè¾“å‡ºshape: {fused_output.shape}")
        print(f"  æœŸæœ›è¾“å‡ºshape: (4, 512)")

        if fused_output.shape == (4, 512):
            print("âœ“ è¾“å‡ºshapeæ­£ç¡®")
            return True
        else:
            print(f"âŒ è¾“å‡ºshapeä¸æ­£ç¡®: æœŸæœ›(4, 512), å®é™…{fused_output.shape}")
            return False

    except Exception as e:
        print(f"âŒ åŒä¼ æ„Ÿå™¨ç¼–ç å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_gpu_support():
    """æµ‹è¯•GPUæ”¯æŒ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•5: GPUæ”¯æŒæµ‹è¯•")
    print("=" * 80)

    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        return True

    print(f"âœ“ CUDAå¯ç”¨")
    print(f"  è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
    print(f"  å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
    print(f"  è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")

    checkpoint_path = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1/network/epoch-0021.pth"

    try:
        print("\nåœ¨GPUä¸Šåˆ›å»ºç¼–ç å™¨...")
        encoder = SparshTactileEncoder(
            checkpoint_path=checkpoint_path,
            output_dim=256,
            freeze_encoder=True
        ).cuda()

        print(f"âœ“ ç¼–ç å™¨ç§»è‡³GPUæˆåŠŸ")

        # GPU forwardæµ‹è¯•
        print("\nGPU forwardæµ‹è¯•...")
        dummy_input = torch.randn(8, 3, 32, 32).cuda()

        with torch.no_grad():
            output = encoder(dummy_input)

        print(f"âœ“ GPU ForwardæˆåŠŸ")
        print(f"  è¾“å…¥device: {dummy_input.device}")
        print(f"  è¾“å‡ºdevice: {output.device}")
        print(f"  è¾“å‡ºshape: {output.shape}")

        return True

    except Exception as e:
        print(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_structure_match():
    """æµ‹è¯•æ¨¡å‹ç»“æ„æ˜¯å¦åŒ¹é…checkpoint"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•6: æ£€æŸ¥æ¨¡å‹ç»“æ„ä¸checkpointåŒ¹é…åº¦")
    print("=" * 80)

    checkpoint_path = "/home/pi-zero/isaac-sim/TacEx/source/tacex_tasks/tacex_tasks/factory_version1/network/epoch-0021.pth"

    try:
        # åŠ è½½checkpoint
        checkpoint = torch.load(checkpoint_path, map_location='cpu')

        if 'model_encoder' not in checkpoint:
            print("âŒ Checkpointä¸­æ²¡æœ‰model_encoder")
            return False

        encoder_state = checkpoint['model_encoder']

        # åˆ›å»ºæ¨¡å‹
        from tactile_ssl.model.vision_transformer import vit_base

        print("\nåˆ›å»ºViT-Baseæ¨¡å‹...")
        model = vit_base(
            img_size=(224, 224),
            patch_size=16,
            in_chans=3,
            pos_embed_fn='learned',
        )

        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

        # å°è¯•åŠ è½½æƒé‡
        print("\nå°è¯•åŠ è½½æƒé‡...")
        missing_keys, unexpected_keys = model.load_state_dict(encoder_state, strict=False)

        print(f"\næƒé‡åŠ è½½ç»“æœ:")
        print(f"  ç¼ºå¤±çš„é”®æ•°é‡: {len(missing_keys)}")
        print(f"  å¤šä½™çš„é”®æ•°é‡: {len(unexpected_keys)}")

        if len(missing_keys) > 0:
            print(f"\n  ç¼ºå¤±çš„é”®ï¼ˆå‰10ä¸ªï¼‰:")
            for key in missing_keys[:10]:
                print(f"    - {key}")

        if len(unexpected_keys) > 0:
            print(f"\n  å¤šä½™çš„é”®ï¼ˆå‰10ä¸ªï¼‰:")
            for key in unexpected_keys[:10]:
                print(f"    - {key}")

        # æ£€æŸ¥å…³é”®å‚æ•°æ˜¯å¦åŠ è½½
        print("\næ£€æŸ¥å…³é”®å‚æ•°:")
        key_params = ['patch_embed.proj.weight', 'pos_embed', 'blocks.0.attn.qkv.weight', 'norm.weight']
        for param_name in key_params:
            if hasattr(model, param_name.split('.')[0]):
                print(f"  âœ“ {param_name} å­˜åœ¨")
            else:
                print(f"  ? {param_name} æ£€æŸ¥")

        # æµ‹è¯•forward
        print("\næµ‹è¯•åŠ è½½æƒé‡åçš„forward...")
        dummy_input = torch.randn(2, 3, 224, 224)
        with torch.no_grad():
            output = model(dummy_input)

        print(f"âœ“ ForwardæˆåŠŸ")
        print(f"  è¾“å‡ºshape: {output.shape}")

        if len(missing_keys) == 0 and len(unexpected_keys) == 0:
            print("\nâœ“ æ¨¡å‹ç»“æ„å®Œå…¨åŒ¹é…checkpoint")
            return True
        else:
            print(f"\nâš  æ¨¡å‹ç»“æ„éƒ¨åˆ†åŒ¹é…ï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬åªéœ€è¦encoderéƒ¨åˆ†ï¼‰")
            return True

    except Exception as e:
        print(f"âŒ ç»“æ„åŒ¹é…æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "=" * 80)
    print("Sparshè§¦è§‰ç¼–ç å™¨æµ‹è¯•")
    print("=" * 80)

    tests = [
        ("Checkpointæ–‡ä»¶æ£€æŸ¥", test_checkpoint_loading),
        ("ç¼–ç å™¨åˆ›å»ºæµ‹è¯•", test_encoder_creation),
        ("åŠ è½½checkpointæµ‹è¯•", test_encoder_with_checkpoint),
        ("åŒä¼ æ„Ÿå™¨ç¼–ç å™¨æµ‹è¯•", test_dual_encoder),
        ("GPUæ”¯æŒæµ‹è¯•", test_gpu_support),
        ("æ¨¡å‹ç»“æ„åŒ¹é…æµ‹è¯•", test_model_structure_match),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\nâŒ {test_name} å‡ºç°å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))

    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)

    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {test_name}")

    total = len(results)
    passed = sum(1 for _, r in results if r)

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¼–ç å™¨å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        print(f"\nâš  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")


if __name__ == "__main__":
    main()
