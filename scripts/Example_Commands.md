# Example Commands
Some example commands for training etc.

To list all TacEx environments:
```bash
# Assuming you are in the TacEx root directory
isaaclab -p scripts/reinforcement_learning/list_envs.py
```

## Training

```bash
isaaclab -p ./scripts/reinforcement_learning/rsl_rl/train.py --task TacEx-Ball-Rolling-IK-v0 --num_envs 1024
```

```bash
isaaclab -p ./scripts/reinforcement_learning/rsl_rl/train.py --task TacEx-Ball-Rolling-Privileged-v0 --num_envs 1024
```

```bash
isaaclab -p ./scripts/reinforcement_learning/rsl_rl/train.py --task TacEx-Ball-Rolling-Privileged-without-Reach_v0 --num_envs 1024 --enable_cameras
```

```bash
isaaclab -p ./scripts/reinforcement_learning/skrl/train.py --task TacEx-Ball-Rolling-Tactile-RGB-Uipc-v0 --num_envs 1 --enable_cameras --checkpoint /workspace/tacex/logs/skrl/ball_rolling/2025-05-16_18-16-16_tactile_rgb_best/checkpoints/best_agent.pt
```

## Play
```bash
isaaclab -p ./scripts/reinforcement_learning/rsl_rl/play.py --task TacEx-Ball-Rolling-Tactile-Base-v1 --num_envs 23 --enable_cameras --load_run logs/skrl/ball_rolling/2025-04-08_22-55-53_improved_ppo_torch_base_env_cluster --checkpoint best_agent.pt
```

```bash
isaaclab -p ./scripts/reinforcement_learning/skrl/play.py --task TacEx-Ball-Rolling-Tactile-RGB-Uipc-v0 --num_envs 23 --enable_cameras --checkpoint logs/skrl/ball_rolling/workspace/tacex/logs/skrl/ball_rolling/2025-05-16_18-16-16_tactile_rgb_best/checkpoints/best_agent.pt
```


## Other
You can activate tensorboard with
```bash
isaaclab -p -m tensorboard.main serve --logdir /workspace/tacex/logs/rsl_rl/ball_rolling
isaaclab -p -m tensorboard.main serve --logdir /workspace/tacex/logs/skrl/ball_rolling
```

You can debug RL training scripts by (for example) running the command
```bash
#python -m pip install --upgrade debugpy
lab -p -m debugpy --listen 3000 --wait-for-client _your_command_
```
and then attaching via VScode debugger.


## è®­ç»ƒpeg insert ä»»åŠ¡
  # ä»æœ€æ–° checkpoint ç»§ç»­è®­ç»ƒ
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --checkpoint logs/rl_games/Factory/test/nn/Factory.pth

  # æˆ–ä½¿ç”¨ç‰¹å®šè¿­ä»£çš„ checkpoint
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --checkpoint logs/rl_games/Factory/test/nn/Factory_1000.pth

  é…ç½®æ–‡ä»¶ä½ç½®:
  IsaacLab/source/isaaclab_tasks/isaaclab_tasks/direct/factory/agents/rl_games_ppo_cfg.yaml

  å…³é”®å‚æ•°: (åœ¨ rl_games_ppo_cfg.yaml:74-76)
  config:
    max_epochs: 200              # æœ€å¤§è®­ç»ƒè½®æ•°(epoch)
    save_best_after: 10          # è®­ç»ƒ10ä¸ªepochåå¼€å§‹ä¿å­˜æœ€ä½³æ¨¡å‹
    save_frequency: 100          # æ¯100ä¸ªepochä¿å­˜ä¸€æ¬¡checkpoint
    horizon_length: 128          # æ¯ä¸ªepochçš„æ­¥æ•°

  è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°:
  æ€»æ­¥æ•° = max_epochs Ã— horizon_length Ã— num_envs
        = 200 Ã— 128 Ã— 128  
        = 3,276,800 æ­¥

  2ï¸âƒ£ å¯è§†åŒ–è®¾ç½®

  æ–¹å¼1: è®­ç»ƒæ—¶ä¸æ˜¾ç¤ºGUI (headlessæ¨¡å¼)
  # é»˜è®¤å°±æ˜¯ headless æ¨¡å¼(æ— GUI),æ›´å¿«
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --headless  # é»˜è®¤å·²å¯ç”¨

  æ–¹å¼2: è®­ç»ƒæ—¶æ˜¾ç¤ºå¯è§†åŒ–
  # ä¸ä½¿ç”¨ headless æ¨¡å¼
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0
      # ä¸åŠ  --headless å‚æ•°

  3ï¸âƒ£ å½•åˆ¶è§†é¢‘è®¾ç½®

  å‘½ä»¤è¡Œå‚æ•°: (åœ¨ train.py:18-20)
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --video \                    # å¯ç”¨è§†é¢‘å½•åˆ¶
      --video_length 200 \          # æ¯ä¸ªè§†é¢‘é•¿åº¦(æ­¥æ•°)
      --video_interval 2000         # æ¯2000æ­¥å½•åˆ¶ä¸€æ¬¡

  è§†é¢‘ä¿å­˜ä½ç½®:
  logs/rl_games/<config_name>/<experiment_name>/videos/train/

  4ï¸âƒ£ å…¶ä»–é‡è¦å‚æ•°

  ç¯å¢ƒé…ç½®: (åœ¨ factory_env_cfg.py:96,119)
  episode_length_s = 10.0        # æ¯ä¸ªepisodeé•¿åº¦(ç§’)
  num_envs = 128                 # å¹¶è¡Œç¯å¢ƒæ•°é‡

  å‘½ä»¤è¡Œè¦†ç›–:
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --num_envs 256 \              # è¦†ç›–ç¯å¢ƒæ•°é‡
      --max_iterations 500 \         # è¦†ç›–æœ€å¤§è®­ç»ƒè½®æ•°
      --seed 42                      # è®¾ç½®éšæœºç§å­

  ğŸ¯ å®Œæ•´è®­ç»ƒå‘½ä»¤ç¤ºä¾‹

  åŸºç¡€è®­ç»ƒ(å¿«é€Ÿ,æ— å¯è§†åŒ–)

  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --num_envs 256 \
      --headless

  è®­ç»ƒ+å½•åˆ¶è§†é¢‘

  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task Isaac-Factory-PegInsert-Direct-v0 \
      --num_envs 128 \
      --video \
      --video_length 200 \
      --video_interval 2000 \
      --headless
## Tacex çš„nut thread


 ## æ¨ç†+å½•åˆ¶è§†é¢‘
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/play.py \
      --task  TacEx-Factory-PegInsert-Direct-v0 \
      --num_envs 1 \
      --enable_cameras \
      --video \
      --video_length 200 \
     --checkpoint  /home/pi-zero/isaac-sim/TacEx/logs/rl_games/Factory/test/nn/last_Factory_ep_400_rew_344.56436.pth

 ## è§¦è§‰ä¸å¼•å…¥ è®­ç»ƒ
  ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task  TacEx-Factory-PegInsert-Direct-v0 \
      --num_envs 128 \
      --enable_cameras \
      --wandb-project-name isaac_lab \
      --wandb-entity 2996124754-salesforce \
      --track
      --headless


## è§¦è§‰å¼•å…¥obs è®­ç»ƒ
       ./IsaacLab/isaaclab.sh -p scripts/reinforcement_learning/rl_games/train.py \
      --task  TacEx-Factory-PegInsert-Tactile-v1 \
      --num_envs 128 \
      --enable_cameras \
      --wandb-project-name isaac_lab_tactile_v1 \
      --wandb-entity 2996124754-salesforce \
      --track
      --headless